# Alphabet_Classification

## OUR Notebook:
**[INS final of preprocessing+ResNet+DenseNet+Xception](https://colab.research.google.com/drive/1xinkXH54_tDKBVU2TZ3hSjmTyu9HAcDW?usp=sharing)**

## Data

The datasets used in this project are as follows: 
- **Arabic Letters Dataset: ahcd1** [Link to Kaggle Dataset](https://www.kaggle.com/datasets/mloey1/ahcd1/code)  
- **English Letters Dataset: emnist** [Link to Kaggle Dataset](https://www.kaggle.com/datasets/crawford/emnist)  

After preprocessing, the combined and split data files are Uploaded to Hugging Face :  
**[combined_arabic_english_letters](https://huggingface.co/datasets/anassaleh218/combined_arabic_english_letters)**
- [`train_data.npy`](https://huggingface.co/datasets/anassaleh218/combined_arabic_english_letters/blob/main/train_data.npy)  
- [`test_data.npy`](https://huggingface.co/datasets/anassaleh218/combined_arabic_english_letters/blob/main/test_data.npy) 
- [`train_labels.npy`](https://huggingface.co/datasets/anassaleh218/combined_arabic_english_letters/blob/main/train_labels.npy)
- [`test_labels.npy`](https://huggingface.co/datasets/anassaleh218/combined_arabic_english_letters/blob/main/test_labels.npy) 

---

## Models

The trained models are hosted on Hugging Face and are organized as follows:  

### ResNet
- **Keras Format**: [Link to ResNet Keras](https://huggingface.co/MennaEssam/resnet_model_keras)  

### DenseNet
- **H5 Format**: [Link to DenseNet H5](https://huggingface.co/anassaleh218/densenet_model_h5)  
- **Keras Format**: [Link to DenseNet Keras](https://huggingface.co/anassaleh218/densenet_model_keras)  

### Xception
- **H5 Format**: [Link to Xception H5](https://huggingface.co/anassaleh218/xception_model_h5)  
- **Keras Format**: [Link to Xception Keras](https://huggingface.co/anassaleh218/xception_model_keras)  

---

## Documentation

For detailed information about the datasets, models, preprocessing steps, and evaluation metrics, refer to the [documentation](#).  
