# Alphabet_Classification

## OUR Notebook:
**[INS final of preprocessing+ResNet+DenseNet+Xception](https://colab.research.google.com/drive/1xinkXH54_tDKBVU2TZ3hSjmTyu9HAcDW?usp=sharing)**

## Data

The datasets used in this project are as follows: 
- **Arabic Letters Dataset**: [Link to Kaggle Dataset: ahcd1](https://www.kaggle.com/datasets/mloey1/ahcd1/code)  
- **English Letters Dataset**: [Link to Kaggle Dataset: emnist](https://www.kaggle.com/datasets/crawford/emnist)  

After preprocessing, the combined and split data files are available here:  
- **[combined_arabic_english_letters](anassaleh218/combined_arabic_english_letters)**
- [`train_data.npy`](https://huggingface.co/datasets/anassaleh218/combined_arabic_english_letters/blob/main/train_data)  
- [`test_data.npy`](https://huggingface.co/datasets/anassaleh218/combined_arabic_english_letters/blob/main/test_data) 
- [`train_labels.npy`](https://huggingface.co/datasets/anassaleh218/combined_arabic_english_letters/blob/main/train_labels)
- [`test_labels.npy`](https://huggingface.co/datasets/anassaleh218/combined_arabic_english_letters/blob/main/test_labels) 

---

## Models

The trained models are hosted on Hugging Face and are organized as follows:  

### ResNet
- **H5 Format**: [Link to ResNet H5](#)  
- **Keras Format**: [Link to ResNet Keras]([#](https://huggingface.co/)MennaEssam/resnet_model_keras)  

### DenseNet
- **H5 Format**: [Link to DenseNet H5](https://huggingface.co/anassaleh218/densenet_model_h5)  
- **Keras Format**: [Link to DenseNet Keras](https://huggingface.co/anassaleh218/densenet_model_keras)  

### Xception
- **H5 Format**: [Link to Xception H5](https://huggingface.co/anassaleh218/xception_model_h5)  
- **Keras Format**: [Link to Xception Keras](https://huggingface.co/anassaleh218/xception_model_keras)  

---

## Documentation

For detailed information about the datasets, models, preprocessing steps, and evaluation metrics, refer to the [documentation](#).  
